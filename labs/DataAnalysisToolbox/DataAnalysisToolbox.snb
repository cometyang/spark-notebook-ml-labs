{
  "metadata" : {
    "name" : "DataAnalysisToolbox",
    "user_save_timestamp" : "1970-01-01T03:00:00.000Z",
    "auto_save_timestamp" : "1970-01-01T03:00:00.000Z",
    "language_info" : {
      "name" : "scala",
      "file_extension" : "scala",
      "codemirror_mode" : "text/x-scala"
    },
    "trusted" : true,
    "customLocalRepo" : null,
    "customRepos" : null,
    "customDeps" : [ "com.databricks:spark-csv_2.10:1.4.0" ],
    "customImports" : null,
    "customArgs" : null,
    "customSparkConf" : null
  },
  "cells" : [ {
    "metadata" : {
      "id" : "95D05E6947F345E89118DB4D3FFFA6B7"
    },
    "cell_type" : "markdown",
    "source" : "## Data Analysis Toolbox"
  }, {
    "metadata" : {
      "id" : "EB9614E2CD184E678F6BC1B93365EF96"
    },
    "cell_type" : "markdown",
    "source" : "In this lab we are going to get familiar with **Breeze** numerical processing library, **Bokeh** plotting library and Spark **DataFrames** (distributed collections of data organized into named columns) in a way of offering little challenges and solving them."
  }, {
    "metadata" : {
      "id" : "51F8A0B8B4CD4E428971A244E456E37B"
    },
    "cell_type" : "markdown",
    "source" : "### Breeze"
  }, {
    "metadata" : {
      "id" : "495A983C298B4D4E835A8D1BA7951D40"
    },
    "cell_type" : "markdown",
    "source" : "* [Quick start tutorial](https://github.com/scalanlp/breeze/wiki/Quickstart)"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "9A1F20BEE5614F5288F63802F1C959D9"
    },
    "cell_type" : "code",
    "source" : "import breeze.linalg._\nimport breeze.stats.{mean, stddev}\nimport breeze.stats.distributions._",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "import breeze.linalg._\nimport breeze.stats.{mean, stddev}\nimport breeze.stats.distributions._\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 3
    } ]
  }, {
    "metadata" : {
      "id" : "DFBA1EA8C73C462B8D8A75B8DF86A8E5"
    },
    "cell_type" : "markdown",
    "source" : "** Problem 1.** Implement a method that takes Matrix X and two sequences ii and jj of equal size as an input and produces breeze.linalg.DenseVector[Double] of elements [X[ii[0], jj[0]], X[ii[1], jj[1]], ..., X[ii[N-1], jj[N-1]]]."
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "D02A774908504FD68919A102A39E9A1B"
    },
    "cell_type" : "code",
    "source" : "def constructVector(X: Matrix[Double], ii: Seq[Int], jj: Seq[Int]): DenseVector[Double] = ???",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "constructVector: (X: breeze.linalg.Matrix[Double], ii: Seq[Int], jj: Seq[Int])breeze.linalg.DenseVector[Double]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 4
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "A57CE7E24EF64E79BF84E5E8B4305A5B"
    },
    "cell_type" : "code",
    "source" : "// Solution for problem 1\ndef constructVector(X: Matrix[Double], ii: Seq[Int], jj: Seq[Int]): DenseVector[Double] =\n  DenseVector(ii.zip(jj).map(ix => X(ix._1, ix._2)).toArray)\n\nconstructVector(DenseMatrix((1.0,2.0,3.0), \n                            (4.0,5.0,6.0), \n                            (7.0, 8.0, 9.0)), \n                List(0, 1, 2), List(0, 1, 2))",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "constructVector: (X: breeze.linalg.Matrix[Double], ii: Seq[Int], jj: Seq[Int])breeze.linalg.DenseVector[Double]\nres7: breeze.linalg.DenseVector[Double] = DenseVector(1.0, 5.0, 9.0)\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "DenseVector(1.0, 5.0, 9.0)"
      },
      "output_type" : "execute_result",
      "execution_count" : 5
    } ]
  }, {
    "metadata" : {
      "id" : "D8CA43DDDF6B40FF90E502D3E8AF8853"
    },
    "cell_type" : "markdown",
    "source" : "** Problem 2. ** Write a method to calculate the product of nonzero elements on the diagonal of a rectangular matrix. For example, for X = Matrix((1.0, 0.0, 1.0), (2.0, 0.0, 2.0), (3.0, 0.0, 3.0), (4.0, 4.0, 4.0)) the answer is Some(3). If there are no nonzero elements, the method should return None."
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "B3D4225AFB974919A498F73F1261CDB2"
    },
    "cell_type" : "code",
    "source" : "def nonzeroProduct(X: Matrix[Double]): Option[Double] = ???",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "nonzeroProduct: (X: breeze.linalg.Matrix[Double])Option[Double]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 6
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "446C8EF7D64F4D39830B992B5C71E7AF"
    },
    "cell_type" : "code",
    "source" : "// Solution for problem 2\ndef nonzeroProduct(X: Matrix[Double]): Option[Double] =\n  (0 until min(X.rows, X.cols)).map(i => X(i, i)).filter(_ != 0) match {\n  case Seq() => None\n  case xs => Some(xs.reduce(_ * _))\n}\n\nnonzeroProduct(Matrix((1.0, 0.0, 1.0), (2.0, 0.0, 2.0), (3.0, 0.0, 3.0), (4.0, 4.0, 4.0)))",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "nonzeroProduct: (X: breeze.linalg.Matrix[Double])Option[Double]\nres10: Option[Double] = Some(3.0)\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "Some(3.0)"
      },
      "output_type" : "execute_result",
      "execution_count" : 7
    } ]
  }, {
    "metadata" : {
      "id" : "923401B0BDF545A79CD054DD311A085A"
    },
    "cell_type" : "markdown",
    "source" : "** Problem 3. ** Write a method to find the maximum element of the vector with the preceding zero element. For example, for Vector(6, 2, 0, 3, 0, 0, 5, 7, 0) the answer is Some(5). If there are no such an elements, the method should return None."
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "EA7AF589BB6647C9B5E822642FEED048"
    },
    "cell_type" : "code",
    "source" : "def maxAfterZeroElement(vec: Vector[Double]): Option[Double] = ???",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "maxAfterZeroElement: (vec: breeze.linalg.Vector[Double])Option[Double]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 8
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "A69FB921286E41FCA109F75D9B698A9F"
    },
    "cell_type" : "code",
    "source" : "def maxAfterZeroElement(vec: Vector[Double]): Option[Double] =\n  vec.toArray.foldLeft((None, false): (Option[Double], Boolean))(\n    (prev: (Option[Double], Boolean), el: Double) =>\n    if (el == 0) {\n      (prev._1, true)\n    } else {\n      prev match {\n        case (p, false) => (p, false)\n        case (None, true) => (Some(el), false)\n        case (Some(m), true) => ({if (el > m) Some(el) else Some(m)}, false)\n      }\n    }\n  )._1",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "maxAfterZeroElement: (vec: breeze.linalg.Vector[Double])Option[Double]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 9
    } ]
  }, {
    "metadata" : {
      "id" : "5FD54847415148EC872CDB23065D42A0"
    },
    "cell_type" : "markdown",
    "source" : "** Problem 4. ** Write a method that takes Matrix X and some number Double v and returns closest matrix element to given number v. For example: for X = new DenseMatrix(2, 5, DenseVector.range(0, 10).mapValues(_.toDouble).toArray) and v = 3.6 the answer would be 4.0."
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "2BEAC9974E47494086A3DFB018508CC2"
    },
    "cell_type" : "code",
    "source" : "def closestValue(X: DenseMatrix[Double], v: Double): Double = ???",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "closestValue: (X: breeze.linalg.DenseMatrix[Double], v: Double)Double\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 10
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "0F75F38E392944A99C10DF4C2826140D"
    },
    "cell_type" : "code",
    "source" : "// Solution for problem 4\nimport scala.math.abs\n\ndef closestValue(X: DenseMatrix[Double], v: Double): Double =\n  X(argmin(X.map(e => abs(e - v))))",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "import scala.math.abs\nclosestValue: (X: breeze.linalg.DenseMatrix[Double], v: Double)Double\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 11
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "2187AA8E3A4542A19A8728D6D6F7761A"
    },
    "cell_type" : "code",
    "source" : "// Another solution for problem 4\nimport breeze.numerics.abs\n\ndef closestValue(X: DenseMatrix[Double], v: Double): Double =\n  X(argmin(abs(X - v)))",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "import breeze.numerics.abs\nclosestValue: (X: breeze.linalg.DenseMatrix[Double], v: Double)Double\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 12
    } ]
  }, {
    "metadata" : {
      "id" : "B8D5C66ED4EB48859128CDCF17BAC141"
    },
    "cell_type" : "markdown",
    "source" : "** Problem 5. ** Write a method that takes Matrix X and scales each column of this matrix by subtracting mean value and dividing by standard deviation of the column. For testing one can generate random matrix. Avoid division by zero."
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "5D942106942C459E850AD8126B2CE709"
    },
    "cell_type" : "code",
    "source" : "def scale(X: DenseMatrix[Double]): Unit = ???",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "scale: (X: breeze.linalg.DenseMatrix[Double])Unit\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 13
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "16F51358CEB846309D858984F38CB4D8"
    },
    "cell_type" : "code",
    "source" : "// Solution for problem 5\ndef scale(X: DenseMatrix[Double]): Unit = {\n  val mm = mean(X(::, *))    // using broadcasting\n  val std = stddev(X(::, *)) // https://github.com/scalanlp/breeze/wiki/Quickstart#broadcasting\n  (0 until X.cols).foreach{i =>\n    if (std(0, i) == 0.0) {\n      X(::, i) := 0.0\n    } else {\n      X(::, i) := (X(::, i) - mm(0, i)) :/ std(0, i)\n    }\n  }\n}",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "scale: (X: breeze.linalg.DenseMatrix[Double])Unit\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 14
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "26EBF924AEC34E28809536FAD8F74D6F"
    },
    "cell_type" : "code",
    "source" : "// Another solution for problem 5\ndef scale(X: DenseMatrix[Double]): Unit =\n  (0 until X.cols).map{i =>\n    val col = X(::, i)\n    val std = stddev(col)\n    if (std != 0.0) {\n      X(::, i) := (col - mean(col)) / std\n    } else {\n      X(::, i) := DenseVector.zeros[Double](col.size)\n    }\n  }",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "scale: (X: breeze.linalg.DenseMatrix[Double])Unit\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 15
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "presentation" : {
        "tabs_state" : "{\n  \"tab_id\": \"#tab301562629-0\"\n}",
        "pivot_chart_state" : "{\n  \"hiddenAttributes\": [],\n  \"menuLimit\": 200,\n  \"cols\": [],\n  \"rows\": [],\n  \"vals\": [],\n  \"exclusions\": {},\n  \"inclusions\": {},\n  \"unusedAttrsVertical\": 85,\n  \"autoSortUnusedAttrs\": false,\n  \"inclusionsInfo\": {},\n  \"aggregatorName\": \"Count\",\n  \"rendererName\": \"Table\"\n}"
      },
      "id" : "4E50151E12884DE88DCACA72B0CD50D7"
    },
    "cell_type" : "code",
    "source" : "// Let's test our scale method on random data\nval nd = new Gaussian(12, 20)\nval m = DenseMatrix.rand(10, 3, nd)\nprintln(m)\nprintln(\"============\")\nscale(m)\nprintln(m)",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "id" : "C4A3752987EE46F18747BCB4C34A4022"
    },
    "cell_type" : "markdown",
    "source" : "** Problem 6. ** Implement a method that for given matrix X finds:\n* the determinant\n* the trace\n* max and min elements\n* Frobenius Norm\n* eigenvalues\n* inverse matrix\n\nFor testing one can generate random matrix from normal distribution $N(10, 1)$."
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "9BD53A5E493848E1BE168CD483002AE5"
    },
    "cell_type" : "code",
    "source" : "def getStats(X: Matrix[Double]): Unit = ???",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "getStats: (X: breeze.linalg.Matrix[Double])Unit\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 52
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "4DDB7D9BF36A482485E3C4E6B380C429"
    },
    "cell_type" : "code",
    "source" : "// Solution for problem 6\ndef getStats(X: DenseMatrix[Double]): String = {\n  val dt = det(X)\n  val tr = trace(X)\n  val minE = min(X)\n  val maxE = max(X)\n  val frob = breeze.linalg.norm(X.toDenseVector)\n  val ev = eig(X).eigenvalues\n  val invM = inv(X)\n  \n  s\"\"\"Stats:\n     |determinant: $dt\n     |trace: $tr\n     |min element: $minE\n     |max element: $maxE\n     |Frobenius Norm: $frob\n     |eigenvalues: $ev\n     |inverse matrix:\\n$invM\"\"\".stripMargin \n}",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "getStats: (X: breeze.linalg.DenseMatrix[Double])String\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 73
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "D784DB3C1C244CCDA1E52E063A34A820"
    },
    "cell_type" : "code",
    "source" : "// Let's test our scale method on random data\nval nd = new Gaussian(10, 1)\nval X = DenseMatrix.rand(4, 4, nd)",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "nd: breeze.stats.distributions.Gaussian = Gaussian(10.0, 1.0)\nX: breeze.linalg.DenseMatrix[Double] = \n9.764669131159627   9.28500301591061    8.956346794609928  10.717348874392329  \n9.268576142991856   10.6934488652767    9.38377044034161   8.856707393443772   \n9.90468891186542    10.767809011199333  7.888834533653101  9.973474205176775   \n10.253806212235116  9.696281372203591   9.921247766873682  9.504578030616202   \n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 76
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "79479A6475BF4C3C9BB94A4B2D9771AB"
    },
    "cell_type" : "code",
    "source" : "println(getStats(X))",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "Stats:\ndeterminant: 59.55982098832586\ntrace: 37.85153056070563\nmin element: 7.888834533653101\nmax element: 10.767809011199333\nFrobenius Norm: 38.82099395136666\neigenvalues: DenseVector(38.70767507560935, 1.4219902080485667, -0.6749621428545479, -1.6031725800977699)\ninverse matrix:\n-0.6804264509362117   -0.8745955402448818  0.5537693552273275    1.0011386128852418     \n-0.13415104487905632  0.4190199801620603   0.14173130426731043   -0.38791278284722774   \n0.19912767025839462   0.39506856339832697  -0.5509366500462      -0.014558764282152414  \n0.6630628180364178    0.10367892714202503  -0.16692284982356664  -0.5639102244057939    \n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 78
    } ]
  }, {
    "metadata" : {
      "id" : "404A38FB45D04DDA8B95411B222E5B32"
    },
    "cell_type" : "markdown",
    "source" : "### DataFrames"
  }, {
    "metadata" : {
      "id" : "A9AB8D7810AC4D9B87264791C4E7B7A3"
    },
    "cell_type" : "markdown",
    "source" : "* https://databricks.com/blog/2015/02/17/introducing-dataframes-in-spark-for-large-scale-data-science.html\n* http://spark.apache.org/docs/latest/sql-programming-guide.html\n"
  }, {
    "metadata" : {
      "id" : "74C7B037A6D3468E8ADC7B908BE2CB5F"
    },
    "cell_type" : "markdown",
    "source" : "In this lab we will be using [data](https://www.kaggle.com/c/titanic/download/train.csv) from [Titanic dataset](https://www.kaggle.com/c/titanic/data).\nTo load data from csv file direct to Spark's Dataframe we will use [spark-csv](http://spark-packages.org/package/databricks/spark-csv) package.\nTo add spark-csv package to spark notebook one could add \"com.databricks:spark-csv_2.10:1.4.0\" (or \"com.databricks:spark-csv_2.11:1.4.0\" for Scala 2.11) dependency into customDeps conf section. Alternatively one could specify this dependency in `--packages` command line option while submiting spark application to a cluster (`spark-submit`) or launching spark shell (`spark-shell`). "
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "872EF7C30A5445EF8396B740C8F8F8E6"
    },
    "cell_type" : "code",
    "source" : "import org.apache.spark.sql.SQLContext",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "import org.apache.spark.sql.SQLContext\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 25
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "F2D176345BC14B5FB8AE1A5B318E735A"
    },
    "cell_type" : "code",
    "source" : "val sqlContext = new SQLContext(sc)\n\nval df = sqlContext.read\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\")\n    .option(\"inferSchema\", \"true\")\n    .load(\"notebooks/labs/DataAnalysisToolbox/titanic.csv\")",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "sqlContext: org.apache.spark.sql.SQLContext = org.apache.spark.sql.SQLContext@65efa115\ndf: org.apache.spark.sql.DataFrame = [PassengerId: int, Survived: int, Pclass: int, Name: string, Sex: string, Age: double, SibSp: int, Parch: int, Ticket: string, Fare: double, Cabin: string, Embarked: string]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 26
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "presentation" : {
        "tabs_state" : "{\n  \"tab_id\": \"#tab775355343-0\"\n}",
        "pivot_chart_state" : "{\n  \"hiddenAttributes\": [],\n  \"menuLimit\": 200,\n  \"cols\": [],\n  \"rows\": [],\n  \"vals\": [],\n  \"exclusions\": {},\n  \"inclusions\": {},\n  \"unusedAttrsVertical\": 85,\n  \"autoSortUnusedAttrs\": false,\n  \"inclusionsInfo\": {},\n  \"aggregatorName\": \"Count\",\n  \"rendererName\": \"Table\"\n}"
      },
      "id" : "CAD8C0E1677C4D34AD5FC421E802C2C3"
    },
    "cell_type" : "code",
    "source" : "// df.show()\ndf.limit(5)",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "res270: org.apache.spark.sql.DataFrame = [PassengerId: int, Survived: int, Pclass: int, Name: string, Sex: string, Age: double, SibSp: int, Parch: int, Ticket: string, Fare: double, Cabin: string, Embarked: string]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "<div class=\"df-canvas\">\n      <script data-this=\"{&quot;dataId&quot;:&quot;anona71a8267b0e685290f433f7bb86e3f16&quot;,&quot;partitionIndexId&quot;:&quot;anonba99d317035acebe79c3f330f7a18e15&quot;,&quot;numPartitions&quot;:1,&quot;dfSchema&quot;:{&quot;type&quot;:&quot;struct&quot;,&quot;fields&quot;:[{&quot;name&quot;:&quot;PassengerId&quot;,&quot;type&quot;:&quot;integer&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;Survived&quot;,&quot;type&quot;:&quot;integer&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;Pclass&quot;,&quot;type&quot;:&quot;integer&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;Name&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;Sex&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;Age&quot;,&quot;type&quot;:&quot;double&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;SibSp&quot;,&quot;type&quot;:&quot;integer&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;Parch&quot;,&quot;type&quot;:&quot;integer&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;Ticket&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;Fare&quot;,&quot;type&quot;:&quot;double&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;Cabin&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;Embarked&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}}]}}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/dataframe','../javascripts/notebook/consoleDir'], \n      function(dataframe, extension) {\n        dataframe.call(data, this, extension);\n      }\n    );/*]]>*/</script>\n      <link rel=\"stylesheet\" href=\"/assets/stylesheets/ipython/css/dataframe.css\" type=\"text/css\"/>\n    </div>"
      },
      "output_type" : "execute_result",
      "execution_count" : 147
    } ]
  }, {
    "metadata" : {
      "id" : "DBF5D59E48644943A1DCF3290EC7724A"
    },
    "cell_type" : "markdown",
    "source" : "**Problem 1.** Describe given dataset by answering following questions. How many women and men were on board? How many passengers were in each class? What is the average/minimum/maximum age of passengers? What can you say about the number of the surviving passengers?"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "4D10AC2744DC4142818107095741FC98"
    },
    "cell_type" : "code",
    "source" : "// Solution for problem 1\nimport org.apache.spark.sql.functions.{min, max, mean}\n\ndf.groupBy(\"Sex\").count().show()\ndf.groupBy(\"Pclass\").count().show()\ndf.select(mean(\"Age\").alias(\"Average Age\"), min(\"Age\"), max(\"Age\")).show()\n\nval totalPassengers = df.count()\nval survived = df.groupBy(\"Survived\").count()\nsurvived.withColumn(\"%\", (survived(\"count\") / totalPassengers) * 100).show()",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "+------+-----+\n|   Sex|count|\n+------+-----+\n|female|  314|\n|  male|  577|\n+------+-----+\n\n+------+-----+\n|Pclass|count|\n+------+-----+\n|     1|  216|\n|     2|  184|\n|     3|  491|\n+------+-----+\n\n+-----------------+--------+--------+\n|      Average Age|min(Age)|max(Age)|\n+-----------------+--------+--------+\n|29.69911764705882|    0.42|    80.0|\n+-----------------+--------+--------+\n\n+--------+-----+-----------------+\n|Survived|count|                %|\n+--------+-----+-----------------+\n|       0|  549|61.61616161616161|\n|       1|  342|38.38383838383838|\n+--------+-----+-----------------+\n\nimport org.apache.spark.sql.functions.{min, max, mean, sum, count}\ntotalPassengers: Long = 891\nsurvived: org.apache.spark.sql.DataFrame = [Survived: int, count: bigint]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 68
    } ]
  }, {
    "metadata" : {
      "id" : "2701E64C61A9449F8D39321805D04617"
    },
    "cell_type" : "markdown",
    "source" : "**Problem 2.** Is it true that women were more likely to survive than men? Who had more chances to survive: the passenger with a cheap ticket or the passenger with an expensive one? Is that true that youngest passengers had more chances to survive?"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "F5F8F9E9230B48198F712BB858E20088"
    },
    "cell_type" : "code",
    "source" : "import org.apache.spark.sql.functions.{sum, count}\nimport org.apache.spark.sql.types.IntegerType",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "import org.apache.spark.sql.functions.{sum, count}\nimport org.apache.spark.sql.types.IntegerType\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 1
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "B5146158FCE840F18D117849A753763D"
    },
    "cell_type" : "code",
    "source" : "// Answer for q1\ndf.groupBy(\"Sex\")\n  .agg((sum(\"Survived\") / count(\"Survived\"))\n       .alias(\"survived part\"))\n.show()",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "+------+-------------------+\n|   Sex|      survived part|\n+------+-------------------+\n|female| 0.7420382165605095|\n|  male|0.18890814558058924|\n+------+-------------------+\n\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 6
    } ]
  }, {
    "metadata" : {
      "id" : "4766317B0FF04ADE8B934A6EBF804F6C"
    },
    "cell_type" : "markdown",
    "source" : "Women were more likely to survive."
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "A28384DB4DE041FC84578CC118E3002D"
    },
    "cell_type" : "code",
    "source" : "// Answer for q2\nval survivedByFareRange = df.select(df(\"Survived\"), \n                                  ((df(\"Fare\") / (df(\"SibSp\") + df(\"Parch\") + 1) / 5).cast(IntegerType)\n                                  ).alias(\"fareRange\"))\n\nsurvivedByFareRange.groupBy(\"fareRange\")\n                   .agg((sum(\"Survived\") / count(\"Survived\")).alias(\"Survived part\"),\n                      count(\"Survived\").alias(\"passengers num\"))\n.sort(\"fareRange\")\n.show()",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "+---------+-------------------+--------------+\n|fareRange|      Survived part|passengers num|\n+---------+-------------------+--------------+\n|        0|0.26744186046511625|            86|\n|        1|0.27058823529411763|           425|\n|        2| 0.4122137404580153|           131|\n|        3| 0.5652173913043478|            23|\n|        4| 0.2222222222222222|             9|\n|        5| 0.5714285714285714|            70|\n|        6|             0.5625|            32|\n|        7|               0.56|            25|\n|        8|                0.6|            15|\n|        9|               0.75|             8|\n|       10| 0.4166666666666667|            12|\n|       11|                0.8|            10|\n|       13|                1.0|             3|\n|       14|               0.25|             4|\n|       15| 0.6666666666666666|             9|\n|       16|                1.0|             3|\n|       17|                1.0|             3|\n|       18|                1.0|             1|\n|       21|                1.0|             3|\n|       22|                1.0|             2|\n+---------+-------------------+--------------+\nonly showing top 20 rows\n\nsurvivedByFareRange: org.apache.spark.sql.DataFrame = [Survived: int, fareRange: int]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 8
    } ]
  }, {
    "metadata" : {
      "id" : "15372F99F9814A52B4D2D2D9C8E2905E"
    },
    "cell_type" : "markdown",
    "source" : "We can see that passengers with cheapest tickets had lowest chances to survive. To obtain ticket cost per passenger we had to divide ticket fare by number of persons (one person itself + number of Siblings/Spouses aboard + number of parents/children aboard) included in fare."
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "68DA8C02FAA8436389AF389C963E9F70"
    },
    "cell_type" : "code",
    "source" : "// Answer for q3\nval survivedByAgeDecade = df.select(df(\"Survived\"), \n                                    ((df(\"Age\") / 10).cast(IntegerType)).alias(\"decade\"))\nsurvivedByAgeDecade.filter(survivedByAgeDecade(\"decade\") >= 0).\n                groupBy(\"decade\")\n                .agg((sum(\"Survived\") / count(\"Survived\")).alias(\"Survived part\"),\n                      count(\"Survived\").alias(\"passengers num\"))\n.sort(\"decade\")\n.show()",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "+------+-------------------+--------------+\n|decade|      Survived part|passengers num|\n+------+-------------------+--------------+\n|     0| 0.6129032258064516|            62|\n|     1| 0.4019607843137255|           102|\n|     2|               0.35|           220|\n|     3|  0.437125748502994|           167|\n|     4|0.38202247191011235|            89|\n|     5| 0.4166666666666667|            48|\n|     6| 0.3157894736842105|            19|\n|     7|                0.0|             6|\n|     8|                1.0|             1|\n+------+-------------------+--------------+\n\nsurvivedByAgeDecade: org.apache.spark.sql.DataFrame = [Survived: int, decade: int]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 9
    } ]
  }, {
    "metadata" : {
      "id" : "EDFE29761BF04E489D3BFAC831A2F7A2"
    },
    "cell_type" : "markdown",
    "source" : "Here we can see that youngest passengers had more chances to survive"
  } ],
  "nbformat" : 4
}